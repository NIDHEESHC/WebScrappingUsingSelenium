{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service= Service(r'C:\\\\chromedriver')) #Driver name is defined as 'driver'\n",
    "driver.get('https://gotoauto.ca/inventory/') # gets the inventory page \n",
    "\n",
    "driver.maximize_window() #maximize window size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//span[@class= \"closy\"]'))) #find the popup close button attributes\n",
    "close_button.click() #clicks the close button\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the number of elements in the pagination bar\n",
    "def page_num():\n",
    "    pagination = driver.find_elements(By.XPATH, '//ul[@class= \"pagination\"]/li') #list of elements in the pagination bar\n",
    "    return len(pagination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "price = []\n",
    "\n",
    "for i in range(page_num()-1): #page_num()-1 because the last element in the pagination bar is next button\n",
    "    car_names = driver.find_elements(By.XPATH, '//div[@class= \"col col-12 rmv-padding xs-hidden bc_layout5\"]') #All car names in page 1\n",
    "    MSRP = driver.find_elements(By.XPATH,'//span[@class=\"price\"]') # curresponing Price\n",
    "    \n",
    "    for cars in car_names:\n",
    "        name.append(cars.text) #append car name to the list, name\n",
    "    for rate in MSRP:\n",
    "        price.append(rate.text) #appends msrp to the list, MSRP\n",
    "    try:\n",
    "        driver.find_element(By.XPATH, '//ul[@class= \"pagination\"]/li[3]/a').click() #try to click the next nutton if exists.\n",
    "    except:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "output = pd.DataFrame({'car_name': name,\n",
    "                            'MSRP':price}) #the name and MSRP list are inputed to a dictionary then made a pandas dataframe\n",
    "output.to_csv('task_1.csv', index= False)# csv output with name task_1.csv\n",
    "# End of Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()#driver goes back to previous page\n",
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task_2\n",
    "cars_list = driver.find_elements(By.XPATH, '//*[@id=\"inventory-list\"]/div[4]/div/div/ul/li/div[2]/div/div[2]/div/div[1]/a') #get the list of web elements for the car name in the first page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_save(Content): # function to write a .txt file with file name car_index.txt\n",
    "\n",
    "     x = 'car_' + str(index) + '.txt' #structure of the output file name\n",
    "     with open(x, \"w\") as file: #open text file x to write\n",
    "          file.write(Content.text) #write the content\n",
    "     \n",
    "\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, single_car in enumerate(cars_list): # for a single element in the list of elements of car names\n",
    "     \n",
    "     \n",
    "     car_link = single_car.get_attribute('href') #get the link from 'href' attribute to the  car page\n",
    "     r = requests.get(car_link) #requests car webpage\n",
    "     soup = BeautifulSoup(r.content)# define soup to request the contents of webpage\n",
    "     para = soup.find(class_ ='col col-12 note_desc_col finance_active')# get the description paragraph with class attribute\n",
    "\n",
    "     file_save(para) #output the description paragraph to text file with file_save function\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit() #terminate the driver"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "867d43fd3ecfa423734fd8db60e39a497fd02dd9c3ae2d7603df295b9af14085"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
